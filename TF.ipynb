{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b03ce45",
   "metadata": {},
   "source": [
    "## TENSORFLOW INPUT PIPELINE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662ace1e",
   "metadata": {},
   "source": [
    "FOR INPUT DATA PIPELINE, WE USE `tf.data` FRAMEWORK AND MAIN CLASS IN THAT IS `tf.data.Dataset`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6b0d6e",
   "metadata": {},
   "source": [
    "FOR FILTER OPERATION TO REMOVE BLUR IMAGE, WE USE `tf_dataset.filter`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2e1bf5",
   "metadata": {},
   "source": [
    "FOR SCALING OPERATION TO STANDARDIZE IMAGE, WE USE `tf_dataset.map(lambda x: x/255)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac5dfaf",
   "metadata": {},
   "source": [
    "FINALLY:  `model.fit(batch)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df541434",
   "metadata": {},
   "source": [
    "BUILDING DATA PIPELINE USING TF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8c24b2",
   "metadata": {},
   "source": [
    "`tf_dataset = tf.data.Dataset.list_files('images/*').map(process_img).filter(filter_func).map(lambda x: x/255)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d02945",
   "metadata": {},
   "source": [
    "TF_DATASET ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dc02752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d243c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_sales_numbers = [23, 21, -19, 45, 98, 34, -45, 0, 56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "346c46bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 13:15:08.959674: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-12-12 13:15:08.959760: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "tf_dataset = tf.data.Dataset.from_tensor_slices(daily_sales_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5222c81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(23, shape=(), dtype=int32)\n",
      "tf.Tensor(21, shape=(), dtype=int32)\n",
      "tf.Tensor(-19, shape=(), dtype=int32)\n",
      "tf.Tensor(45, shape=(), dtype=int32)\n",
      "tf.Tensor(98, shape=(), dtype=int32)\n",
      "tf.Tensor(34, shape=(), dtype=int32)\n",
      "tf.Tensor(-45, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(56, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for sales in tf_dataset:\n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b8d8f6",
   "metadata": {},
   "source": [
    "ALL VALUES INSIDE LIST HAS BEEN CONVERTED INTO TENSORS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fe5e4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "21\n",
      "-19\n",
      "45\n",
      "98\n",
      "34\n",
      "-45\n",
      "0\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "for sales in tf_dataset:\n",
    "    print(sales.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec87cab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "21\n",
      "-19\n",
      "45\n",
      "98\n",
      "34\n",
      "-45\n",
      "0\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "for sales in tf_dataset.as_numpy_iterator():\n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73c67fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(23, shape=(), dtype=int32)\n",
      "tf.Tensor(21, shape=(), dtype=int32)\n",
      "tf.Tensor(-19, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for sales in tf_dataset.take(3):\n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0e05da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "21\n",
      "-19\n"
     ]
    }
   ],
   "source": [
    "for sales in tf_dataset.take(3):\n",
    "    print(sales.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4e53ec",
   "metadata": {},
   "source": [
    "FILTER OPERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95901b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "21\n",
      "45\n",
      "98\n",
      "34\n",
      "56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 13:15:09.033898: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "tf_dataset = tf_dataset.filter(lambda x: x>0)\n",
    "for sales in tf_dataset.as_numpy_iterator():\n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff952e72",
   "metadata": {},
   "source": [
    "MAPPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9cdeb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1656\n",
      "1512\n",
      "3240\n",
      "7056\n",
      "2448\n",
      "4032\n"
     ]
    }
   ],
   "source": [
    "tf_dataset = tf_dataset.map(lambda x: x*72)\n",
    "for sales in tf_dataset.as_numpy_iterator():\n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d15ea0a",
   "metadata": {},
   "source": [
    "SHUFFLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30ed6ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1656\n",
      "3240\n",
      "7056\n",
      "1512\n",
      "2448\n",
      "4032\n"
     ]
    }
   ],
   "source": [
    "tf_dataset = tf_dataset.shuffle(3)\n",
    "for sales in tf_dataset.as_numpy_iterator():\n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1fbd86",
   "metadata": {},
   "source": [
    "BATCHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f9ee896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3240 1656 7056]\n",
      "[2448 4032 1512]\n"
     ]
    }
   ],
   "source": [
    "for sales_batch in tf_dataset.batch(3):\n",
    "    print(sales_batch.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871baacc",
   "metadata": {},
   "source": [
    "PERFORMING ALL THE ABOVE OPERATION IN ONE LINE USING TF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c9bf33",
   "metadata": {},
   "source": [
    "## ETL USING TF INPUT PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01e5e25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7665 8395]\n",
      "[16425 35770]\n",
      "[20440 12410]\n"
     ]
    }
   ],
   "source": [
    "tf_dataset = tf.data.Dataset.from_tensor_slices(daily_sales_numbers)\n",
    "\n",
    "tf_dataset_yearly = tf_dataset.filter(lambda x: x > 0).map(lambda y: y*365).shuffle(2).batch(2)\n",
    "\n",
    "for sales in tf_dataset_yearly.as_numpy_iterator():\n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edbe8717",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_ds = tf.data.Dataset.list_files('images/*/*', shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "602ce8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'images/cats/cat.2000.jpg'\n",
      "b'images/cats/cat.2001.jpg'\n",
      "b'images/cats/cat.2002.jpg'\n",
      "b'images/cats/cat.2003.jpg'\n",
      "b'images/cats/cat.2004.jpg'\n"
     ]
    }
   ],
   "source": [
    "for file in images_ds.take(5):\n",
    "    print(file.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2791a82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'images/dogs/dog.2195.jpg'\n",
      "b'images/cats/cat.2363.jpg'\n",
      "b'images/dogs/dog.2335.jpg'\n",
      "b'images/dogs/dog.2164.jpg'\n",
      "b'images/dogs/dog.2292.jpg'\n"
     ]
    }
   ],
   "source": [
    "image_ds = images_ds.shuffle(2500)\n",
    "\n",
    "for file in image_ds.take(5):\n",
    "    print(file.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7af8a08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['cat', 'dog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a99d718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_count = len(image_ds)\n",
    "image_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a482846",
   "metadata": {},
   "source": [
    "TRAIN-TEST SPLIT IN TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2279cf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(image_count * 0.85)\n",
    "\n",
    "train_ds = image_ds.take(train_size)\n",
    "test_ds = image_ds.skip(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7f41626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "850\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "print(len(train_ds))\n",
    "print(len(test_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4321af82",
   "metadata": {},
   "source": [
    "`take` will include all the file paths from the directory.\n",
    "\n",
    "`skip` will include all the file paths ignored by take from the directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92a0314",
   "metadata": {},
   "source": [
    "REMOVING THE LABELS FROM THE IMAGE PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f70a971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cats'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'images/cats/cat.2000.jpg'\n",
    "s.split('/')[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6acf5a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def get_label(file_path):\n",
    "    return tf.strings.split(file_path, os.path.sep)[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91e314d",
   "metadata": {},
   "source": [
    "PROCESSING THE INPUT TRAINING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d05c78e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(file_path):\n",
    "    label = get_label(file_path)\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = tf.image.decode_jpeg(img)\n",
    "    img = tf.image.resize(img, [128,128])\n",
    "    \n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79af4862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'images/cats/cat.2290.jpg'\n",
      "b'images/cats/cat.2024.jpg'\n",
      "b'images/dogs/dog.2183.jpg'\n"
     ]
    }
   ],
   "source": [
    "for t in train_ds.take(3):\n",
    "    print(t.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5889f498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image:  tf.Tensor(\n",
      "[[[ 16.453125  17.453125  11.453125]\n",
      "  [ 18.359375  19.359375  13.359375]\n",
      "  [ 19.        20.        14.      ]\n",
      "  ...\n",
      "  [ 33.265625  34.265625  28.265625]\n",
      "  [ 28.359375  29.359375  23.359375]\n",
      "  [ 78.24219   79.24219   73.24219 ]]\n",
      "\n",
      " [[ 16.453125  17.453125  11.453125]\n",
      "  [ 18.359375  19.359375  13.359375]\n",
      "  [ 19.        20.        14.      ]\n",
      "  ...\n",
      "  [ 33.265625  34.265625  28.265625]\n",
      "  [ 28.359375  29.359375  23.359375]\n",
      "  [ 82.85156   83.85156   77.85156 ]]\n",
      "\n",
      " [[ 16.453125  17.453125  11.453125]\n",
      "  [ 18.359375  19.359375  13.359375]\n",
      "  [ 19.        20.        14.      ]\n",
      "  ...\n",
      "  [ 33.265625  34.265625  28.265625]\n",
      "  [ 28.359375  29.359375  23.359375]\n",
      "  [ 84.39844   85.39844   79.39844 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 80.06775   80.06775   70.24475 ]\n",
      "  [ 76.41406   76.41406   66.55444 ]\n",
      "  [ 77.734375  77.734375  67.838135]\n",
      "  ...\n",
      "  [ 39.872803  35.984985  20.797485]\n",
      "  [ 32.859497  29.094238  15.445435]\n",
      "  [ 40.171875  31.651001  22.278687]]\n",
      "\n",
      " [[ 77.546875  78.546875  72.546875]\n",
      "  [ 73.75781   74.75781   68.75781 ]\n",
      "  [ 75.11719   76.11719   70.11719 ]\n",
      "  ...\n",
      "  [ 39.913696  64.14795   37.56201 ]\n",
      "  [ 38.362793  54.01123   30.308105]\n",
      "  [ 40.21875   48.507812  29.804688]]\n",
      "\n",
      " [[ 79.        80.        74.      ]\n",
      "  [ 77.078125  78.078125  72.078125]\n",
      "  [ 78.03906   79.03906   73.03906 ]\n",
      "  ...\n",
      "  [ 60.156372 113.333374  71.20581 ]\n",
      "  [ 59.256226 105.479614  66.309326]\n",
      "  [ 54.265625  91.46094   57.304688]]], shape=(128, 128, 3), dtype=float32)\n",
      "Label:  tf.Tensor(b'dogs', shape=(), dtype=string)\n",
      "Image:  tf.Tensor(\n",
      "[[[192.56787  238.56787  251.56787 ]\n",
      "  [194.       240.       253.      ]\n",
      "  [194.6875   240.6875   253.6875  ]\n",
      "  ...\n",
      "  [156.44238  170.83643  184.08643 ]\n",
      "  [202.77588  243.03369  250.38574 ]\n",
      "  [192.8374   232.04297  244.10156 ]]\n",
      "\n",
      " [[193.03857  239.03857  252.03857 ]\n",
      "  [194.68896  240.68896  253.68896 ]\n",
      "  [195.61719  241.61719  254.61719 ]\n",
      "  ...\n",
      "  [179.10059  190.54834  204.67871 ]\n",
      "  [169.27393  202.43799  213.79102 ]\n",
      "  [195.7749   226.5415   243.90869 ]]\n",
      "\n",
      " [[194.04346  241.04346  251.04346 ]\n",
      "  [195.75244  242.75244  252.75244 ]\n",
      "  [196.79053  243.79053  253.79053 ]\n",
      "  ...\n",
      "  [195.22998  200.75049  219.17383 ]\n",
      "  [203.11719  225.2085   241.54199 ]\n",
      "  [187.52588  203.62305  228.76367 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[229.52783  216.52783  197.52783 ]\n",
      "  [205.48633  192.48633  173.48633 ]\n",
      "  [231.21191  218.21191  201.52441 ]\n",
      "  ...\n",
      "  [139.5      104.10791  136.21094 ]\n",
      "  [115.42041   86.68359  109.319336]\n",
      "  [140.52783  118.40283  131.17969 ]]\n",
      "\n",
      " [[207.89795  194.89795  175.89795 ]\n",
      "  [202.3877   189.3877   170.3877  ]\n",
      "  [214.16602  201.16602  184.47852 ]\n",
      "  ...\n",
      "  [131.84424   91.31299  121.930176]\n",
      "  [120.771484  88.01367  109.691895]\n",
      "  [144.14062  121.226074 133.73389 ]]\n",
      "\n",
      " [[211.83936  198.83936  179.83936 ]\n",
      "  [208.0708   195.0708   176.0708  ]\n",
      "  [218.51709  205.51709  188.82959 ]\n",
      "  ...\n",
      "  [190.20215  144.59717  175.10742 ]\n",
      "  [174.64844  138.91309  160.81299 ]\n",
      "  [145.93213  121.77344  134.84082 ]]], shape=(128, 128, 3), dtype=float32)\n",
      "Label:  tf.Tensor(b'dogs', shape=(), dtype=string)\n",
      "Image:  tf.Tensor(\n",
      "[[[ 98.87341    80.87341    58.873413 ]\n",
      "  [ 89.48715    71.2106     53.272705 ]\n",
      "  [ 88.91861    71.56122    57.796234 ]\n",
      "  ...\n",
      "  [ 53.733093   48.363983   53.13153  ]\n",
      "  [ 58.189087   52.64731    57.587524 ]\n",
      "  [ 56.644928   50.93048    56.043365 ]]\n",
      "\n",
      " [[103.89957    86.860504   66.78238  ]\n",
      "  [117.569305  100.5603     82.5423   ]\n",
      "  [ 88.03293    71.931366   58.880585 ]\n",
      "  ...\n",
      "  [ 73.78113    62.824097   61.083893 ]\n",
      "  [ 78.07846    66.58237    65.20856  ]\n",
      "  [ 73.382416   61.34726    60.339844 ]]\n",
      "\n",
      " [[112.61865    98.001465   78.83804  ]\n",
      "  [113.93738    99.234314   83.05066  ]\n",
      "  [100.7554     86.714935   75.61337  ]\n",
      "  ...\n",
      "  [ 75.96735    55.908752   46.654846 ]\n",
      "  [ 98.128845   77.890564   69.17572  ]\n",
      "  [106.62109    86.203125   78.02734  ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 61.449158   49.21869    46.83197  ]\n",
      "  [ 62.740204   55.47458    51.417908 ]\n",
      "  [ 63.55078    57.695312   50.652344 ]\n",
      "  ...\n",
      "  [ 37.3757     23.375702   20.375702 ]\n",
      "  [ 35.896515   21.896515   18.896515 ]\n",
      "  [ 36.764984   22.764984   19.764984 ]]\n",
      "\n",
      " [[ 62.2106     50.0282     46.422333 ]\n",
      "  [ 68.92697    61.32779    55.62738  ]\n",
      "  [ 61.173737   54.16388    46.27133  ]\n",
      "  ...\n",
      "  [ 32.03131    18.148499   15.031311 ]\n",
      "  [ 31.311646   17.428833   14.3116455]\n",
      "  [ 33.63202    19.749207   16.632019 ]]\n",
      "\n",
      " [[ 68.640625   57.640625   53.640625 ]\n",
      "  [ 62.820312   49.78125    46.460938 ]\n",
      "  [ 64.30859    51.26953    47.94922  ]\n",
      "  ...\n",
      "  [ 34.05078    23.050781   17.050781 ]\n",
      "  [ 33.308594   22.308594   16.308594 ]\n",
      "  [ 29.         18.         12.       ]]], shape=(128, 128, 3), dtype=float32)\n",
      "Label:  tf.Tensor(b'dogs', shape=(), dtype=string)\n",
      "Image:  tf.Tensor(\n",
      "[[[ 24.563843  26.384155  20.179688]\n",
      "  [ 31.00476   25.735352  39.56726 ]\n",
      "  [ 68.5166    56.270508  75.77832 ]\n",
      "  ...\n",
      "  [145.71875  127.71875  103.71875 ]\n",
      "  [145.71875  127.71875  103.71875 ]\n",
      "  [147.67712  126.28125  105.28125 ]]\n",
      "\n",
      " [[ 28.1604    26.797241  40.070312]\n",
      "  [ 74.25354   67.56958   89.89807 ]\n",
      "  [116.140625 103.89453  123.15625 ]\n",
      "  ...\n",
      "  [145.84375  127.84375  103.84375 ]\n",
      "  [145.84375  127.84375  103.84375 ]\n",
      "  [149.46875  128.46875  107.46875 ]]\n",
      "\n",
      " [[ 68.60828   65.70984   88.15906 ]\n",
      "  [111.18323  104.7926   125.63245 ]\n",
      "  [122.184326 111.34448  122.42883 ]\n",
      "  ...\n",
      "  [143.40625  125.40625  101.40625 ]\n",
      "  [145.19983  127.19983  103.19983 ]\n",
      "  [146.40625  130.40625  104.40625 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[157.59375  150.78125  138.375   ]\n",
      "  [160.07031  152.52283  142.39905 ]\n",
      "  [148.75854  140.94604  131.55225 ]\n",
      "  ...\n",
      "  [ 68.50073   46.14685   42.360107]\n",
      "  [ 71.59888   50.822754  56.568237]\n",
      "  [115.505615 100.6261    93.27014 ]]\n",
      "\n",
      " [[145.0503   146.0503   138.0503  ]\n",
      "  [156.75317  155.7102   147.36255 ]\n",
      "  [166.32751  163.83533  151.83533 ]\n",
      "  ...\n",
      "  [ 63.46338   39.817627  42.55591 ]\n",
      "  [ 72.90845   58.56079   48.951416]\n",
      "  [136.83948  123.83948  105.737915]]\n",
      "\n",
      " [[163.2019   164.2019   156.2019  ]\n",
      "  [157.81213  156.76917  148.42151 ]\n",
      "  [165.39111  162.89893  150.89893 ]\n",
      "  ...\n",
      "  [ 63.961548  45.330933  45.892334]\n",
      "  [100.17615   82.707275  73.750244]\n",
      "  [150.74219  136.39453  118.74219 ]]], shape=(128, 128, 3), dtype=float32)\n",
      "Label:  tf.Tensor(b'dogs', shape=(), dtype=string)\n",
      "Image:  tf.Tensor(\n",
      "[[[ 50.35376    83.35376    90.75366  ]\n",
      "  [ 43.69873    76.69873    84.12402  ]\n",
      "  [ 52.543457   85.54346    93.793945 ]\n",
      "  ...\n",
      "  [  3.043213   13.043213   14.273682 ]\n",
      "  [  1.6467285   9.123291   10.5998535]\n",
      "  [  2.4335938   8.433594    6.4335938]]\n",
      "\n",
      " [[ 47.354004   81.24634    92.72119  ]\n",
      "  [ 48.749268   82.634766   94.147705 ]\n",
      "  [ 53.779053   87.44238   100.193115 ]\n",
      "  ...\n",
      "  [  1.         11.         12.230469 ]\n",
      "  [  3.4375     10.9140625  12.390625 ]\n",
      "  [  1.7539062   7.7539062   5.7539062]]\n",
      "\n",
      " [[ 48.924072   84.63086   101.5105   ]\n",
      "  [ 56.324707   92.016846  108.94043  ]\n",
      "  [ 52.40869    87.624756  105.97656  ]\n",
      "  ...\n",
      "  [  3.0144043  13.014404   14.244873 ]\n",
      "  [  3.7851562  11.261719   12.738281 ]\n",
      "  [  4.3239746  10.323975    8.323975 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 37.261475   48.261475   34.261475 ]\n",
      "  [ 44.906982   55.906982   41.906982 ]\n",
      "  [ 50.625      61.625      47.625    ]\n",
      "  ...\n",
      "  [ 23.305908   30.349121   23.334717 ]\n",
      "  [ 10.890625   21.721924   13.460205 ]\n",
      "  [ 22.413818   41.675537   30.92163  ]]\n",
      "\n",
      " [[ 36.107666   47.107666   33.107666 ]\n",
      "  [ 45.777344   56.777344   42.777344 ]\n",
      "  [ 44.422607   55.422607   41.422607 ]\n",
      "  ...\n",
      "  [ 24.715576   25.153076   17.567139 ]\n",
      "  [ 15.1640625  20.846436   13.731934 ]\n",
      "  [ 27.415771   42.798584   35.46875  ]]\n",
      "\n",
      " [[ 34.953857   45.953857   31.953857 ]\n",
      "  [ 47.263916   58.263916   44.263916 ]\n",
      "  [ 38.54712    49.54712    35.54712  ]\n",
      "  ...\n",
      "  [ 31.762451   26.863281   20.215088 ]\n",
      "  [ 15.074219   16.335938   10.597656 ]\n",
      "  [ 22.253174   34.2688     27.760986 ]]], shape=(128, 128, 3), dtype=float32)\n",
      "Label:  tf.Tensor(b'dogs', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "train_ds = train_ds.map(process_image)\n",
    "for img, label in train_ds.take(5):\n",
    "    print(\"Image: \", img)\n",
    "    print(\"Label: \", label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24a968c",
   "metadata": {},
   "source": [
    "SCALING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "362daf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(image, label):\n",
    "    return image/255, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2dc378ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image:  [0.1797325  0.18365407 0.16404623]\n",
      "Label:  b'dogs'\n",
      "Image:  [0.00420544 0.00420544 0.01204858]\n",
      "Label:  b'dogs'\n",
      "Image:  [0. 0. 0.]\n",
      "Label:  b'cats'\n",
      "Image:  [0.48600367 0.2637151  0.15783273]\n",
      "Label:  b'cats'\n",
      "Image:  [0.63715124 0.5077395  0.29989636]\n",
      "Label:  b'cats'\n"
     ]
    }
   ],
   "source": [
    "train_ds = train_ds.map(scale)\n",
    "for image, label in train_ds.take(5):\n",
    "    print(\"Image: \", image.numpy()[0][0])\n",
    "    print(\"Label: \", label.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a117638d",
   "metadata": {},
   "source": [
    "OPTIMIZE THE TENSORFLOW PIPELINE PERFORMANCE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccae5bb8",
   "metadata": {},
   "source": [
    "OPTIMIZING THE PERFORMANCE MEANS REDUCING THE TIME TO TRAIN THE MODEL. IN THIS CASE WE MAKE OUR CPU AND GPU BOTH WORK TOGETHER. DURING THE TIME WHEN OUR GPU IS ENGAGED IN TRAINING THE MODEL, CPU WILL PREPARE THE NEXT BATCH TO BE READY FOR TRAINING."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945586ff",
   "metadata": {},
   "source": [
    "FOR THIS OPERATION WE USE:\n",
    "\n",
    "## PREFETCH\n",
    "\n",
    "`tf.data.Dataset.prefetch(no. of batch we want to make ready in CPU)`\n",
    "\n",
    "WE WANT MAKE OPTIMAL USE OF OUR HARDWARES. WE CAN LET TF DECIDE HOW TO DO IT. SO WE CAN PROVIDE `AUTOTUNE`\n",
    "\n",
    "`tf.data.Dataset.prefetch(AUTOTUNE)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a07f820",
   "metadata": {},
   "source": [
    "## CACHING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b01020f",
   "metadata": {},
   "source": [
    "WE HAVE A SERIES OF OPERATIONS TO PERFORM IN DATA PREPROCESSING STAGE. IN EVERY EPOCH WHEN WE PERFORM THE TRAINING, EVERYTIME WE DO ALL THE OPERATION AGAIN LIKE MAP, FILTER ETC. TO AVOID THIS WE USE CACHING. CACHING SAVES TIME AND RESOURCES."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d16bb5e",
   "metadata": {},
   "source": [
    "LETS SEE HOW TRAINING NORMALLY HAPPENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "241f01ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "943db2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileDataset(tf.data.Dataset):\n",
    "    def read_files_in_batches(num_samples):\n",
    "        #open file\n",
    "        time.sleep(0.03)\n",
    "        for sample_idx in range(num_samples):\n",
    "            time.sleep(0.015)\n",
    "            yield(sample_idx,)\n",
    "            \n",
    "    def __new__(cls, num_samples=5):\n",
    "        return tf.data.Dataset.from_generator(\n",
    "            cls.read_files_in_batches,\n",
    "            output_signature = tf.TensorSpec(shape = (1,), dtype = tf.int64),\n",
    "            args = (num_samples,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83188232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(dataset, num_epochs=100):\n",
    "    for epoch_num in range(num_epochs):\n",
    "        for sample in dataset:\n",
    "            time.sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0611750a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1 µs, sys: 1 µs, total: 2 µs\n",
      "Wall time: 2.86 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "benchmark(FileDataset())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0f7638",
   "metadata": {},
   "source": [
    "NOW WE WILL USE PREFETCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30c8cb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 3 µs, total: 6 µs\n",
      "Wall time: 13.1 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "benchmark(FileDataset().prefetch(tf.data.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5356bdc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 3 µs, total: 6 µs\n",
      "Wall time: 11 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "benchmark(FileDataset().prefetch(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a496ed",
   "metadata": {},
   "source": [
    "LETS USE CACHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b1066664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(5)\n",
    "for d in dataset:\n",
    "    print(d.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d6c69a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "4\n",
      "9\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(lambda x: x ** 2)\n",
    "for d in dataset:\n",
    "    print(d.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1a3b89c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "4\n",
      "9\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.cache()\n",
    "\n",
    "for d in dataset.as_numpy_iterator():\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f39a9c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 9, 16]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dataset.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f335b9",
   "metadata": {},
   "source": [
    "It is reading the data from the cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b399b6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapped_function(s):\n",
    "    tf.py_function(lambda: time.sleep(0.03), [], ())\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5bb1a0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 2 µs, total: 5 µs\n",
      "Wall time: 10 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "benchmark(FileDataset().map(mapped_function), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f35334a",
   "metadata": {},
   "source": [
    "PERFORMANCE WITH CACHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "06685ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 1 µs, total: 6 µs\n",
      "Wall time: 11 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "benchmark(FileDataset().map(mapped_function).cache(), 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
